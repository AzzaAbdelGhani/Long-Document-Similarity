{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e816cedd",
   "metadata": {},
   "source": [
    "# Overview Notebook:\n",
    "\n",
    "This notebook contains an overview of the work done of Long Document Similarity  project. Starting from the dataset used for this purpose and the proposed models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f142a2",
   "metadata": {},
   "source": [
    "## 1 Datasets :\n",
    "\n",
    "Two datasets(wines and video_games) extracted from Wikipedia have been used in this project, the link source of the dataset is [here](https://zenodo.org/record/4468783#.Yb-fKOrMJhH). \n",
    "\n",
    "In (/data/Ground-Truth) folder, we can find ground-truth labels for each dataset, and in (data/Load_dataset) we can find the calss (WikipediaLongDocumentSimilarityDataset(Dataset)) which creates a Dataset object for each dataset, load the raw data and ground-truth labels. \n",
    "\n",
    "Next cells show how to use this class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98b54fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size : 1662\n",
      "Number of ground-truth articles: 89\n"
     ]
    }
   ],
   "source": [
    "from data import Load_dataset\n",
    "\n",
    "wines_data = Load_dataset.WikipediaLongDocumentSimilarityDataset(dataset_name = \"wines\") #Load wines dataset\n",
    "print(\"dataset size : {}\".format(len(wines_data))) # print the length of the dataset, which is number of articles\n",
    "print(\"Number of ground-truth articles: {}\".format(len(wines_data.labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316ef868",
   "metadata": {},
   "source": [
    "Each atticle in the dataset has a title and sections, and each section has a section_title and a description. Each article has different number of sections, An example of an article in this dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25d1467d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alphonse Tchami', '[[\"\", \"Alphonse Marie Tchami Djomaha (born 14 September 1971) is a Cameroonian former professional footballer who played as a striker. At international level, he represented Cameroon at the 1994 and 1998 FIFA World Cups.\\\\n\\\\n\"], [\"Club career.\", \"Born in Kekem, Tchami began his career in Cameroon with Unisport Bafang before moving to Danish club Vejle BK. In his short spell at Vejle he scored 8 goals in 15 games, but was unable to prevent the club being relegated. Tchami\\'s spell at Vejle led to interest from other Danish clubs and Tchami eventually moved to Odense BK (OB). Tchami was a part of the OB team that defeated Real Madrid in the 1994\\\\u201395 UEFA Cup third round by 4\\\\u20133 on aggregate, earning a place in the quarter-finals.\\\\n\\\\nTchami joined Argentinian club Boca Juniors shortly after the 1994 FIFA World Cup. In total Tchami played 50 games and scored 11 goals for Boca. After three years he returned to Europe with German side Hertha BSC. Tchami spent two season with Hertha before a spell in the United Arab Emirates with Al-Wasl.\\\\n\\\\nTchami was on trial with Bolton Wanderers in July 2000 following his release, playing in friendly matches on Bolton\\'s tour of Denmark, before signing for Dundee United in August. Tchami spent four months at the Scottish club, leaving in December after playing in four matches and failing to score. Nice was Tchami\\'s next club, where he signed a short-term contract until the end of the season. In August 2001, Tchami left France - putting what was termed a \\\\\"bad spell\\\\\" behind him - and moved to Russian club Chernomorets, before moving again, this time to Shenyang Ginde in China. He signed for Lebanese club Nejmeh in September 2003 but left after less than three weeks, ending his career back in France with amateur side \\\\u00c9pernay. His club career spanned twelve clubs in ten countries over four continents.\\\\n\\\\n\"], [\"International career.\", \"Tchami played in 57 matches for Cameroon and was a participant at the 1994 and 1998 FIFA World Cups, in addition to the 1994 and 1996 African Cup of Nations.\\\\n\\\\n\"], [\"Personal life.\", \"Tchami is from a family of footballers. His three younger brothers also played professionally: Bertrand, former Grenoble Foot 38 and Stade de Reims player, Jo\\\\u00ebl, and Herv\\\\u00e9.\\\\n\\\\n\"]]']\n"
     ]
    }
   ],
   "source": [
    "print(wines_data.articles[765])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd3658a",
   "metadata": {},
   "source": [
    "Each wiki_title in ground-truth has different number of similar articles, an example of ground-truth labels of an article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11941c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An Example of ground-truth Labels for 'Champagne in popular culture' article :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Sparkling wine': 1,\n",
       " 'Champagne Krug': 1,\n",
       " 'Moët &amp; Chandon': 1,\n",
       " 'Champagne Riots': 1,\n",
       " 'Champagne wine region': 1,\n",
       " 'History of French wine': 1,\n",
       " 'Dom Pérignon': 1}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"An Example of ground-truth Labels for 'Champagne in popular culture' article :\")\n",
    "wines_data.labels['Champagne in popular culture']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff320101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size : 21228\n",
      "Number of ground-truth articles: 88\n"
     ]
    }
   ],
   "source": [
    "#To Load video_games dataset \n",
    "games_data = Load_dataset.WikipediaLongDocumentSimilarityDataset(dataset_name = \"video_games\") \n",
    "print(\"dataset size : {}\".format(len(games_data))) \n",
    "print(\"Number of ground-truth articles: {}\".format(len(games_data.labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a65b55",
   "metadata": {},
   "source": [
    "## 2 Baselines Models :\n",
    "\n",
    "Two Baselines model have been implemented to find the similar articles of each article in ground-truth, and then the results are compared to ground-truth labels. \n",
    "\n",
    "### 2.1 TF_IDF Model :\n",
    "\n",
    "The implementation can be found [here](https://github.com/AzzaAbdelGhani/Long-Document-Similarity/blob/main/models/TFIDF.py), where [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) is used to build Tf-IDF features matrix. TF_IDF (Term Frequency_ Inverse Document Frequency) model mainly represents each article as a **weight vector** of **N** dimension, where N is the number of tokens in the article, and each component is the weight of the coressponding token, this weight reflect how important a token is to an article in the dataset. \n",
    "\n",
    "After creating TF-IDF matrix features, we compute the similarity score between articles by using *cosine_similarity* and then sort the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d8cc72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Find k = 1662 Similar articles: 100%|███████████| 89/89 [00:01<00:00, 65.19it/s]\n"
     ]
    }
   ],
   "source": [
    "from models.TFIDF import TF_IDF \n",
    "\n",
    "tfidf_model_1 = TF_IDF(dataset_name=\"wines\")\n",
    "#For this model , we find the (k = 1662) similar articles for each wiki_article in ground-Truth articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef9f709b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF matrix size : (1662, 65968)\n"
     ]
    }
   ],
   "source": [
    "print(\"TFIDF matrix size : {}\".format(tfidf_model_1.tfidf_matrix.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c7625ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Find k = 21228 Similar articles: 100%|██████████| 88/88 [00:23<00:00,  3.78it/s]\n"
     ]
    }
   ],
   "source": [
    "tfidf_model_2 = TF_IDF(dataset_name=\"video_games\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b418d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF matrix size : (21228, 203022)\n"
     ]
    }
   ],
   "source": [
    "print(\"TFIDF matrix size : {}\".format(tfidf_model_2.tfidf_matrix.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b348f62a",
   "metadata": {},
   "source": [
    "### 2.2 SBERT Model :\n",
    "\n",
    "The implementation can be found [here](https://github.com/AzzaAbdelGhani/Long-Document-Similarity/blob/main/models/SBERT.py), where [SentenceTransformer](https://www.sbert.net/) is used to compute sentence embeddings, and then we compute article's embeddings. Article's embedding is the average of sentences' embeddings that article contains. And then by using *faiss*, we find similarity scores between articles.\n",
    "\n",
    "This model is run on GPU, and output embeddings of articles for each dataset is saved in (/data/saved_embeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c841b210",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These libraries need to be installed to call SBERT class\n",
    "#!pip install faiss-gpu\n",
    "#!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c983b039",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Find k = 1661 Similar articles: 100%|███████████| 89/89 [00:00<00:00, 98.58it/s]\n",
      "Find k = 21227 Similar articles: 100%|██████████| 88/88 [00:13<00:00,  6.70it/s]\n"
     ]
    }
   ],
   "source": [
    "from models.SBERT import SBERT\n",
    "\n",
    "#This loads the articles embeddings saved in \"all-MiniLM-L6-v2_wines_embeddings.pkl\" for wines dataset, and compute similarities\n",
    "SBERT_wines = SBERT(\"wines\", saved_embeddings= \"data/saved_embeddings/all-MiniLM-L6-v2_wines_embeddings.pkl\")\n",
    "\n",
    "#This loads articles embeddings of video_games dataset\n",
    "SBERT_games = SBERT(\"video_games\", saved_embeddings= \"data/saved_embeddings/all-MiniLM-L6-v2_video_games_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957881e4",
   "metadata": {},
   "source": [
    "## 3 Evaluation Metrics :\n",
    "\n",
    "There metrics are used for evaluation : **Mean Percentile Ranking (MPR)**, **Mean Reciprocal Rank (MRR)** and **Hit-Ratio @ k (HR@k)**\n",
    "\n",
    "By running *main* method in [main.py](https://github.com/AzzaAbdelGhani/Long-Document-Similarity/blob/main/main.py), we can see these metrics reults for each model for each dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e53bde58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This libraby is required to show the results in a nice table\n",
    "#!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "386572f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Find k = 21227 Similar articles: 100%|██████████| 88/88 [00:11<00:00,  7.54it/s]\n",
      "Find k = 100 Similar articles: 100%|████████████| 88/88 [00:11<00:00,  7.53it/s]\n",
      "Find k = 1661 Similar articles: 100%|███████████| 89/89 [00:00<00:00, 89.22it/s]\n",
      "Find k = 100 Similar articles: 100%|███████████| 89/89 [00:00<00:00, 100.36it/s]\n",
      "Find k = 21228 Similar articles: 100%|██████████| 88/88 [00:22<00:00,  3.88it/s]\n",
      "Find k = 100 Similar articles: 100%|████████████| 88/88 [00:22<00:00,  3.84it/s]\n",
      "Find k = 1662 Similar articles: 100%|███████████| 89/89 [00:01<00:00, 62.93it/s]\n",
      "Find k = 100 Similar articles: 100%|████████████| 89/89 [00:01<00:00, 62.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Results : \n",
      "\n",
      "-----------------------------------------------------------------\n",
      "| \t  |   \t video_games  \t     |   \t wines \t        |\n",
      "-----------------------------------------------------------------\n",
      "| Model   | MPR   | MRR   | HR@100   | MPR   | MRR   | HR@100   |\n",
      "|---------|-------|-------|----------|-------|-------|----------|\n",
      "| SBERT   | 29.5% | 29.8% | 19.9%    | 32.9% | 19.3% | 24.0%    |\n",
      "| TF-IDF  | 35.0% | 43.2% | 11.6%    | 38.6% | 24.1% | 6.3%     |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from main import main\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
